<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="WWei"><title>Pod 错误排查 · 嘟嘟喵喵小白秋裤</title><meta name="description" content="Pod 异常排错本章介绍 Pod 运行异常的排错方法。
一般来说，无论 Pod 处于什么异常状态，都可以执行以下命令来查看 Pod 的状态

kubectl get pod &amp;lt;pod-name&amp;gt; -o yaml 查看 Pod 的配置是否正确
kubectl describe pod &amp;l"><meta name="keywords" content="GO,PHP,K8S,Docker,Kubernetes,Istio,项目管理,创业,生活"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title><a href="/">嘟嘟喵喵小白秋裤</a></h3><div class="description"><p>没有困难创造困难~</p></div></div></div><ul class="social-links"><li><a href="http://github.com/lyzhang1999"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div><script async src="https://www.googletagmanager.com/gtag/js?id=UA-35043271-2"></script><script type="text/javascript">window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-35043271-2');</script></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/logo.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Pod 错误排查</a></h3></div><div class="post-content"><h1 id="Pod-异常排错"><a href="#Pod-异常排错" class="headerlink" title="Pod 异常排错"></a>Pod 异常排错</h1><p>本章介绍 Pod 运行异常的排错方法。</p>
<p>一般来说，无论 Pod 处于什么异常状态，都可以执行以下命令来查看 Pod 的状态</p>
<ul>
<li><code>kubectl get pod &lt;pod-name&gt; -o yaml</code> 查看 Pod 的配置是否正确</li>
<li><code>kubectl describe pod &lt;pod-name&gt;</code> 查看 Pod 的事件</li>
<li><code>kubectl logs &lt;pod-name&gt; [-c &lt;container-name&gt;]</code> 查看容器日志</li>
</ul>
<p>这些事件和日志通常都会有助于排查 Pod 发生的问题。</p>
<h2 id="Pod-一直处于-Pending-状态"><a href="#Pod-一直处于-Pending-状态" class="headerlink" title="Pod 一直处于 Pending 状态"></a>Pod 一直处于 Pending 状态</h2><p>Pending 说明 Pod 还没有调度到某个 Node 上面。可以通过 <code>kubectl describe pod &lt;pod-name&gt;</code> 命令查看到当前 Pod 的事件，进而判断为什么没有调度。如</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod mypod</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason            Age                From               Message</span><br><span class="line">  ----     ------            ----               ----               -------</span><br><span class="line">  Warning  FailedScheduling  12s (x6 over 27s)  default-scheduler  0/4 nodes are available: 2 Insufficient cpu.</span><br></pre></td></tr></table></figure>

<p>可能的原因包括</p>
<ul>
<li>资源不足，集群内所有的 Node 都不满足该 Pod 请求的 CPU、内存、GPU 或者临时存储空间等资源。解决方法是删除集群内不用的 Pod 或者增加新的 Node。</li>
<li>HostPort 端口已被占用，通常推荐使用 Service 对外开放服务端口</li>
</ul>
<h2 id="Pod-一直处于-Waiting-或-ContainerCreating-状态"><a href="#Pod-一直处于-Waiting-或-ContainerCreating-状态" class="headerlink" title="Pod 一直处于 Waiting 或 ContainerCreating 状态"></a>Pod 一直处于 Waiting 或 ContainerCreating 状态</h2><p>首先还是通过 <code>kubectl describe pod &lt;pod-name&gt;</code> 命令查看到当前 Pod 的事件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system describe pod nginx-pod</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason                 Age               From               Message</span><br><span class="line">  ----     ------                 ----              ----               -------</span><br><span class="line">  Normal   Scheduled              1m                default-scheduler  Successfully assigned nginx-pod to node1</span><br><span class="line">  Normal   SuccessfulMountVolume  1m                kubelet, gpu13     MountVolume.SetUp succeeded <span class="keyword">for</span> volume <span class="string">"config-volume"</span></span><br><span class="line">  Normal   SuccessfulMountVolume  1m                kubelet, gpu13     MountVolume.SetUp succeeded <span class="keyword">for</span> volume <span class="string">"coredns-token-sxdmc"</span></span><br><span class="line">  Warning  FailedSync             2s (x4 over 46s)  kubelet, gpu13     Error syncing pod</span><br><span class="line">  Normal   SandboxChanged         1s (x4 over 46s)  kubelet, gpu13     Pod sandbox changed, it will be killed and re-created.</span><br></pre></td></tr></table></figure>

<p>可以发现，该 Pod 的 Sandbox 容器无法正常启动，具体原因需要查看 Kubelet 日志：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ journalctl -u kubelet</span><br><span class="line">...</span><br><span class="line">Mar 14 04:22:04 node1 kubelet[29801]: E0314 04:22:04.649912   29801 cni.go:294] Error adding network: failed to <span class="built_in">set</span> bridge addr: <span class="string">"cni0"</span> already has an IP address different from 10.244.4.1/24</span><br><span class="line">Mar 14 04:22:04 node1 kubelet[29801]: E0314 04:22:04.649941   29801 cni.go:243] Error <span class="keyword">while</span> adding to cni network: failed to <span class="built_in">set</span> bridge addr: <span class="string">"cni0"</span> already has an IP address different from 10.244.4.1/24</span><br><span class="line">Mar 14 04:22:04 node1 kubelet[29801]: W0314 04:22:04.891337   29801 cni.go:258] CNI failed to retrieve network namespace path: Cannot find network namespace <span class="keyword">for</span> the terminated container <span class="string">"c4fd616cde0e7052c240173541b8543f746e75c17744872aa04fe06f52b5141c"</span></span><br><span class="line">Mar 14 04:22:05 node1 kubelet[29801]: E0314 04:22:05.965801   29801 remote_runtime.go:91] RunPodSandbox from runtime service failed: rpc error: code = 2 desc = NetworkPlugin cni failed to <span class="built_in">set</span> up pod <span class="string">"nginx-pod"</span> network: failed to <span class="built_in">set</span> bridge addr: <span class="string">"cni0"</span> already has an IP address different from 10.244.4.1/24</span><br></pre></td></tr></table></figure>

<p>发现是 cni0 网桥配置了一个不同网段的 IP 地址导致，删除该网桥（网络插件会自动重新创建）即可修复</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ip link <span class="built_in">set</span> cni0 down</span><br><span class="line">$ brctl delbr cni0</span><br></pre></td></tr></table></figure>

<p>除了以上错误，其他可能的原因还有</p>
<ul>
<li>镜像拉取失败，比如<ul>
<li>配置了错误的镜像</li>
<li>Kubelet 无法访问镜像（国内环境访问 <code>gcr.io</code> 需要特殊处理）</li>
<li>私有镜像的密钥配置错误</li>
<li>镜像太大，拉取超时（可以适当调整 kubelet 的 <code>--image-pull-progress-deadline</code> 和 <code>--runtime-request-timeout</code> 选项）</li>
</ul>
</li>
<li>CNI 网络错误，一般需要检查 CNI 网络插件的配置，比如<ul>
<li>无法配置 Pod 网络</li>
<li>无法分配 IP 地址</li>
</ul>
</li>
<li>容器无法启动，需要检查是否打包了正确的镜像或者是否配置了正确的容器参数</li>
</ul>
<h2 id="Pod-处于-ImagePullBackOff-状态"><a href="#Pod-处于-ImagePullBackOff-状态" class="headerlink" title="Pod 处于 ImagePullBackOff 状态"></a>Pod 处于 ImagePullBackOff 状态</h2><p>这通常是镜像名称配置错误或者私有镜像的密钥配置错误导致。这种情况可以使用 <code>docker pull &lt;image&gt;</code> 来验证镜像是否可以正常拉取。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod mypod</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason                 Age                From                                Message</span><br><span class="line">  ----     ------                 ----               ----                                -------</span><br><span class="line">  Normal   Scheduled              36s                default-scheduler                   Successfully assigned sh to k8s-agentpool1-38622806-0</span><br><span class="line">  Normal   SuccessfulMountVolume  35s                kubelet, k8s-agentpool1-38622806-0  MountVolume.SetUp succeeded <span class="keyword">for</span> volume <span class="string">"default-token-n4pn6"</span></span><br><span class="line">  Normal   Pulling                17s (x2 over 33s)  kubelet, k8s-agentpool1-38622806-0  pulling image <span class="string">"a1pine"</span></span><br><span class="line">  Warning  Failed                 14s (x2 over 29s)  kubelet, k8s-agentpool1-38622806-0  Failed to pull image <span class="string">"a1pine"</span>: rpc error: code = Unknown desc = Error response from daemon: repository a1pine not found: does not exist or no pull access</span><br><span class="line">  Warning  Failed                 14s (x2 over 29s)  kubelet, k8s-agentpool1-38622806-0  Error: ErrImagePull</span><br><span class="line">  Normal   SandboxChanged         4s (x7 over 28s)   kubelet, k8s-agentpool1-38622806-0  Pod sandbox changed, it will be killed and re-created.</span><br><span class="line">  Normal   BackOff                4s (x5 over 25s)   kubelet, k8s-agentpool1-38622806-0  Back-off pulling image <span class="string">"a1pine"</span></span><br><span class="line">  Warning  Failed                 1s (x6 over 25s)   kubelet, k8s-agentpool1-38622806-0  Error: ImagePullBackOff</span><br></pre></td></tr></table></figure>

<p>如果是私有镜像，需要首先创建一个 docker-registry 类型的 Secret</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL</span><br></pre></td></tr></table></figure>

<p>然后在容器中引用这个 Secret</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">private-reg-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">&lt;your-private-image&gt;</span></span><br><span class="line"><span class="attr">  imagePullSecrets:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">my-secret</span></span><br></pre></td></tr></table></figure>

<h2 id="Pod-一直处于-CrashLoopBackOff-状态"><a href="#Pod-一直处于-CrashLoopBackOff-状态" class="headerlink" title="Pod 一直处于 CrashLoopBackOff 状态"></a>Pod 一直处于 CrashLoopBackOff 状态</h2><p>CrashLoopBackOff 状态说明容器曾经启动了，但又异常退出了。此时 Pod 的 RestartCounts 通常是大于 0 的，可以先查看一下容器的日志</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pod &lt;pod-name&gt;</span><br><span class="line">kubectl logs &lt;pod-name&gt;</span><br><span class="line">kubectl logs --previous &lt;pod-name&gt;</span><br></pre></td></tr></table></figure>

<p>这里可以发现一些容器退出的原因，比如</p>
<ul>
<li>容器进程退出</li>
<li>健康检查失败退出</li>
<li>OOMKilled</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod mypod</span><br><span class="line">...</span><br><span class="line">Containers:</span><br><span class="line">  sh:</span><br><span class="line">    Container ID:  docker://3f7a2ee0e7e0e16c22090a25f9b6e42b5c06ec049405bc34d3aa183060eb4906</span><br><span class="line">    Image:         alpine</span><br><span class="line">    Image ID:      docker-pullable://alpine@sha256:7b848083f93822dd21b0a2f14a110bd99f6efb4b838d499df6d04a49d0debf8b</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    State:          Terminated</span><br><span class="line">      Reason:       OOMKilled</span><br><span class="line">      Exit Code:    2</span><br><span class="line">    Last State:     Terminated</span><br><span class="line">      Reason:       OOMKilled</span><br><span class="line">      Exit Code:    2</span><br><span class="line">    Ready:          False</span><br><span class="line">    Restart Count:  3</span><br><span class="line">    Limits:</span><br><span class="line">      cpu:     1</span><br><span class="line">      memory:  1G</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        100m</span><br><span class="line">      memory:     500M</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>如果此时如果还未发现线索，还可以到容器内执行命令来进一步查看退出原因</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> cassandra -- cat /var/<span class="built_in">log</span>/cassandra/system.log</span><br></pre></td></tr></table></figure>

<p>如果还是没有线索，那就需要 SSH 登录该 Pod 所在的 Node 上，查看 Kubelet 或者 Docker 的日志进一步排查了</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Query Node</span></span><br><span class="line">kubectl get pod &lt;pod-name&gt; -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment"># SSH to Node</span></span><br><span class="line">ssh &lt;username&gt;@&lt;node-name&gt;</span><br></pre></td></tr></table></figure>

<h2 id="Pod-处于-Error-状态"><a href="#Pod-处于-Error-状态" class="headerlink" title="Pod 处于 Error 状态"></a>Pod 处于 Error 状态</h2><p>通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括</p>
<ul>
<li>依赖的 ConfigMap、Secret 或者 PV 等不存在</li>
<li>请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等</li>
<li>违反集群的安全策略，比如违反了 PodSecurityPolicy 等</li>
<li>容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定</li>
</ul>
<h2 id="Pod-处于-Terminating-或-Unknown-状态"><a href="#Pod-处于-Terminating-或-Unknown-状态" class="headerlink" title="Pod 处于 Terminating 或 Unknown 状态"></a>Pod 处于 Terminating 或 Unknown 状态</h2><p>从 v1.5 开始，Kubernetes 不会因为 Node 失联而删除其上正在运行的 Pod，而是将其标记为 Terminating 或 Unknown 状态。想要删除这些状态的 Pod 有三种方法：</p>
<ul>
<li>从集群中删除该 Node。使用公有云时，kube-controller-manager 会在 VM 删除后自动删除对应的 Node。而在物理机部署的集群中，需要管理员手动删除 Node（如 <code>kubectl delete node &lt;node-name&gt;</code>。</li>
<li>Node 恢复正常。Kubelet 会重新跟 kube-apiserver 通信确认这些 Pod 的期待状态，进而再决定删除或者继续运行这些 Pod。</li>
<li>用户强制删除。用户可以执行 <code>kubectl delete pods &lt;pod&gt; --grace-period=0 --force</code> 强制删除 Pod。除非明确知道 Pod 的确处于停止状态（比如 Node 所在 VM 或物理机已经关机），否则不建议使用该方法。特别是 StatefulSet 管理的 Pod，强制删除容易导致脑裂或者数据丢失等问题。</li>
</ul>
<p>如果 Kubelet 是以 Docker 容器的形式运行的，此时 kubelet 日志中可能会发现<a href="https://github.com/kubernetes/kubernetes/issues/51835" target="_blank" rel="noopener">如下的错误</a>：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"log"</span>:<span class="string">"I0926 19:59:07.162477   54420 kubelet.go:1894] SyncLoop (DELETE, \"api\"): \"billcenter-737844550-26z3w_meipu(30f3ffec-a29f-11e7-b693-246e9607517c)\"\n"</span>,<span class="attr">"stream"</span>:<span class="string">"stderr"</span>,<span class="attr">"time"</span>:<span class="string">"2017-09-26T11:59:07.162748656Z"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"log"</span>:<span class="string">"I0926 19:59:39.977126   54420 reconciler.go:186] operationExecutor.UnmountVolume started for volume \"default-token-6tpnm\" (UniqueName: \"kubernetes.io/secret/30f3ffec-a29f-11e7-b693-246e9607517c-default-token-6tpnm\") pod \"30f3ffec-a29f-11e7-b693-246e9607517c\" (UID: \"30f3ffec-a29f-11e7-b693-246e9607517c\") \n"</span>,<span class="attr">"stream"</span>:<span class="string">"stderr"</span>,<span class="attr">"time"</span>:<span class="string">"2017-09-26T11:59:39.977438174Z"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"log"</span>:<span class="string">"E0926 19:59:39.977461   54420 nestedpendingoperations.go:262] Operation for \"\\\"kubernetes.io/secret/30f3ffec-a29f-11e7-b693-246e9607517c-default-token-6tpnm\\\" (\\\"30f3ffec-a29f-11e7-b693-246e9607517c\\\")\" failed. No retries permitted until 2017-09-26 19:59:41.977419403 +0800 CST (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume \"default-token-6tpnm\" (UniqueName: \"kubernetes.io/secret/30f3ffec-a29f-11e7-b693-246e9607517c-default-token-6tpnm\") pod \"30f3ffec-a29f-11e7-b693-246e9607517c\" (UID: \"30f3ffec-a29f-11e7-b693-246e9607517c\") : remove /var/lib/kubelet/pods/30f3ffec-a29f-11e7-b693-246e9607517c/volumes/kubernetes.io~secret/default-token-6tpnm: device or resource busy\n"</span>,<span class="attr">"stream"</span>:<span class="string">"stderr"</span>,<span class="attr">"time"</span>:<span class="string">"2017-09-26T11:59:39.977728079Z"</span>&#125;</span><br></pre></td></tr></table></figure>

<p>如果是这种情况，则需要给 kubelet 容器设置 <code>--containerized</code> 参数并传入以下的存储卷</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以使用 calico 网络插件为例</span></span><br><span class="line">      -v /:/rootfs:ro,shared \</span><br><span class="line">      -v /sys:/sys:ro \</span><br><span class="line">      -v /dev:/dev:rw \</span><br><span class="line">      -v /var/<span class="built_in">log</span>:/var/<span class="built_in">log</span>:rw \</span><br><span class="line">      -v /run/calico/:/run/calico/:rw \</span><br><span class="line">      -v /run/docker/:/run/docker/:rw \</span><br><span class="line">      -v /run/docker.sock:/run/docker.sock:rw \</span><br><span class="line">      -v /usr/lib/os-release:/etc/os-release \</span><br><span class="line">      -v /usr/share/ca-certificates/:/etc/ssl/certs \</span><br><span class="line">      -v /var/lib/docker/:/var/lib/docker:rw,shared \</span><br><span class="line">      -v /var/lib/kubelet/:/var/lib/kubelet:rw,shared \</span><br><span class="line">      -v /etc/kubernetes/ssl/:/etc/kubernetes/ssl/ \</span><br><span class="line">      -v /etc/kubernetes/config/:/etc/kubernetes/config/ \</span><br><span class="line">      -v /etc/cni/net.d/:/etc/cni/net.d/ \</span><br><span class="line">      -v /opt/cni/bin/:/opt/cni/bin/ \</span><br></pre></td></tr></table></figure>

<p>处于 <code>Terminating</code> 状态的 Pod 在 Kubelet 恢复正常运行后一般会自动删除。但有时也会出现无法删除的情况，并且通过 <code>kubectl delete pods &lt;pod&gt; --grace-period=0 --force</code> 也无法强制删除。此时一般是由于 <code>finalizers</code> 导致的，通过 <code>kubectl edit</code> 将 finalizers 删除即可解决。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">"finalizers":</span> <span class="string">[</span></span><br><span class="line">  <span class="string">"foregroundDeletion"</span></span><br><span class="line"><span class="string">]</span></span><br></pre></td></tr></table></figure>

<h2 id="Pod-行为异常"><a href="#Pod-行为异常" class="headerlink" title="Pod 行为异常"></a>Pod 行为异常</h2><p>这里所说的行为异常是指 Pod 没有按预期的行为执行，比如没有运行 podSpec 里面设置的命令行参数。这一般是 podSpec yaml 文件内容有误，可以尝试使用 <code>--validate</code> 参数重建容器，比如</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete pod mypod</span><br><span class="line">kubectl create --validate -f mypod.yaml</span><br></pre></td></tr></table></figure>

<p>也可以查看创建后的 podSpec 是否是对的，比如</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod mypod -o yaml</span><br></pre></td></tr></table></figure>

<h2 id="修改静态-Pod-的-Manifest-后未自动重建"><a href="#修改静态-Pod-的-Manifest-后未自动重建" class="headerlink" title="修改静态 Pod 的 Manifest 后未自动重建"></a>修改静态 Pod 的 Manifest 后未自动重建</h2><p>Kubelet 使用 inotify 机制检测 <code>/etc/kubernetes/manifests</code> 目录（可通过 Kubelet 的 <code>--pod-manifest-path</code> 选项指定）中静态 Pod 的变化，并在文件发生变化后重新创建相应的 Pod。但有时也会发生修改静态 Pod 的 Manifest 后未自动创建新 Pod 的情景，此时一个简单的修复方法是重启 Kubelet。</p>
<h2 id="Nginx-启动失败"><a href="#Nginx-启动失败" class="headerlink" title="Nginx 启动失败"></a>Nginx 启动失败</h2><p>Nginx 启动失败，错误消息是 <code>nginx: [emerg] socket() [::]:8000 failed (97: Address family not supported by protocol)</code>。这是由于服务器未开启 IPv6 导致的，解决方法有两种：</p>
<ul>
<li>第一种方法，服务器开启 IPv6；</li>
<li>或者，第二种方法，删除或者注释掉 <code>/etc/nginx/conf.d/default.conf</code> 文件中的 <code>listen       [::]:80 default_server;</code>。</li>
</ul>
<h3 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h3><ul>
<li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/" target="_blank" rel="noopener">Troubleshoot Applications</a></li>
<li><a href="https://github.com/feiskyer/kubernetes-handbook/edit/master/troubleshooting/pod.md" target="_blank" rel="noopener">Kubernetes-handbook</a></li>
</ul>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2019-08-09</span><i class="fa fa-tag"></i><a class="tag" href="/tags/Kubernetes/" title="Kubernetes">Kubernetes </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://yoursite.com/2019/08/09/Pod错误排查/,嘟嘟喵喵小白秋裤,Pod 错误排查,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2019/08/10/Spring Cloud 无法部署到 K8S 的原因/" title="Spring Cloud 项目部署 K8S 无法启动的原因">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2019/08/09/Istio 核心配置对象/" title="Istio 核心配置对象">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>